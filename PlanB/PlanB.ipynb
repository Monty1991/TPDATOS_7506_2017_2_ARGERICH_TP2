{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproceso del set de entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones del uso de informacion del campo de descripcion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def isFloat(x):\n",
    "    try:\n",
    "        float(x)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "false = 0\n",
    "true = 1\n",
    "# ------------------------------------------------------------------------------\n",
    "# INICIALIZAR DICCIONARIO\n",
    "# ------------------------------------------------------------------------------\n",
    "# pre: Recibe una lista de claves\n",
    "# pos: devuelve un diccionario de esas claves recibidas inicializadas en cero\n",
    "\n",
    "def inicializar_diccionario(keys):\n",
    "    dicc = {}\n",
    "    for charac in keys:\n",
    "        dicc[charac] = 0\n",
    "    return dicc\n",
    "\n",
    "#------------------------------------------------------\n",
    "# GET SURFACE\n",
    "#------------------------------------------------------\n",
    "def getSurface(df):\n",
    "    surfaces = df['surface_total_in_m2'].tolist()\n",
    "    if 'description' not in df:\n",
    "        return surfaces\n",
    "    dfSize = len(df.index)\n",
    "    descriptions = df['description'].tolist()\n",
    "    for i in range(0, dfSize):\n",
    "        if type(descriptions[i]) != type(\"\"):\n",
    "            validateSurface(surfaces[i], 0)\n",
    "            continue\n",
    "        surfaceCalculated = 0\n",
    "        words = descriptions[i].split()\n",
    "        wordsSize = len(words)\n",
    "        for pos in range(0, wordsSize):\n",
    "            surfaceCalculated, offset, iFound = findSurface(words, pos, surfaceCalculated)\n",
    "            if iFound:\n",
    "                pos += offset\n",
    "        surfaces[i] = validateSurface(surfaces[i], surfaceCalculated)\n",
    "    return surfaces\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# VALIDATE SURFACE\n",
    "# ------------------------------------------------------------------------------\n",
    "def validateSurface(surface, surfaceCalculated):\n",
    "    if np.isnan(surface):\n",
    "        return surfaceCalculated\n",
    "    if surface != surfaceCalculated:\n",
    "        return surface\n",
    "    if surface == surfaceCalculated:\n",
    "        return surface\n",
    "    \n",
    "# ------------------------------------------------------------------------------\n",
    "# ENCONTRAR SUPERFICIE\n",
    "# ------------------------------------------------------------------------------\n",
    "def findSurface(words, i, surface):\n",
    "    size = len(words)\n",
    "    offset = 0 \n",
    "    iFound = False\n",
    "    if isFloat(words[i]):\n",
    "        if (i + 2 < size) and words[i+1].lower() == \"x\" and isFloat(words[i+2]):\n",
    "            a = float(words[i])\n",
    "            b = float(words[i+2])        \n",
    "            surface += a*b\n",
    "            return surface, offset, iFound\n",
    "    return surface, offset, iFound\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# ENCONTRAR CANTIDAD DE AMBIENTES\n",
    "# ------------------------------------------------------------------------------\n",
    "def FindsNumberOfRooms(words, i, numberOfRooms):\n",
    "    rooms = [\n",
    "        \"living\", \n",
    "        \"comedor\", \n",
    "        \"cocina\", \n",
    "        \"lavadero\", \n",
    "        \"dormitorio\", \n",
    "        \"vestidor\",\n",
    "        \"baño\"\n",
    "    ]\n",
    "    end = False\n",
    "    size = len(words)\n",
    "    if words[i].isdigit():\n",
    "        if (i + 1 < size) and words[i+1].lower() == \"ambientes\":\n",
    "            numberOfRooms = int(words[i])\n",
    "            return numberOfRooms, end\n",
    "        if (i + 1 < size) and words[i+1].lower() == \"dormitorios\":\n",
    "            numberOfRooms += int(words[i])\n",
    "            return numberOfRooms, not end\n",
    "    if words[i].lower in rooms:\n",
    "        numberOfRooms += 1\n",
    "        return numberOfRooms, not end\n",
    "    return numberOfRooms, not end\n",
    "\n",
    "#------------------------------------------------------\n",
    "# VALIDATE ROOM\n",
    "#------------------------------------------------------\n",
    "def validateRoom(numberOfRooms, numberOfRoomsCalculated):\n",
    "    if np.isnan(numberOfRooms):\n",
    "        return numberOfRoomsCalculated\n",
    "    if numberOfRooms != numberOfRoomsCalculated:\n",
    "        return numberOfRooms\n",
    "    if numberOfRooms == numberOfRoomsCalculated:\n",
    "        return numberOfRooms\n",
    "    \n",
    "#------------------------------------------------------\n",
    "# GET ROOMS\n",
    "#------------------------------------------------------\n",
    "def getRooms(df):\n",
    "    rooms = df['rooms'].tolist()\n",
    "    if 'description' not in df:\n",
    "        return rooms\n",
    "    dfSize = len(df.index)\n",
    "    descriptions = df['description'].tolist()\n",
    "    for i in range(0, dfSize):\n",
    "        if type(descriptions[i]) != type(\"\"):\n",
    "            validateRoom(rooms[i], 0)\n",
    "            continue\n",
    "        numberOfRooms = 0\n",
    "        words = descriptions[i].split()\n",
    "        wordsSize = len(words)\n",
    "        for pos in range(0, wordsSize):\n",
    "            numberOfRooms, end = FindsNumberOfRooms(words, pos, numberOfRooms)\n",
    "            if end:\n",
    "                break\n",
    "        rooms[i] = validateRoom(rooms[i], numberOfRooms)\n",
    "    return rooms\n",
    "# ------------------------------------------------------------------------------\n",
    "# ENCONTRAR FRASE\n",
    "# ------------------------------------------------------------------------------\n",
    "# pre: Recibe un vector de palabras, la posicion en ese vector que se\n",
    "# esta leyendo, y un vector de frases\n",
    "# pos: Devuelve una tripla que dice si alguna de las frases en el\n",
    "# vector \"phrases\", el offset el cual debe desplazarse la posicion de lectura\n",
    "# del vector \"words\" y el indice en donde se encuantrala frase encontrada en el\n",
    "# vector \"phrases\"\n",
    "\n",
    "def encontrar_frase(words, i, phrases):\n",
    "    offset = 0\n",
    "    index = 0\n",
    "    for phrase in phrases:\n",
    "        if words[i].lower() in phrase:\n",
    "            phrase_split = phrase.split()\n",
    "            size = len(phrase_split)\n",
    "            offset = size\n",
    "            index = phrases.index(phrase)\n",
    "            for j in range(0, size):\n",
    "                if (i + j < size) and (words[i + j] != phrase_split[j]):\n",
    "                    return False, offset, index\n",
    "            return True, offset, index\n",
    "    return False, offset, index\n",
    "\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# CREAR DICCIONARIO DESCRIPCION\n",
    "# ------------------------------------------------------------------------------\n",
    "# pre: Recibe un dataframe\n",
    "# pos: Devuelve una lista de diccionarios\n",
    "\n",
    "def crear_diccionario_descripcion(df):\n",
    "    characteristics = [\n",
    "        \"living\",\n",
    "        \"cochera\",\n",
    "        \"comedor\",\n",
    "        \"pileta\",\n",
    "        \"piscina\"\n",
    "    ]\n",
    "    phrases = [\n",
    "        \"cancha de tenis\",\n",
    "        \"club house\",\n",
    "        \"sector de juegos infantiles\",\n",
    "        \"futbol 5\",\n",
    "        \"seguridad las 24 hs\"\n",
    "    ]\n",
    "    size = len(df.index)\n",
    "    dicc_list = []\n",
    "    for i in range(0, size):\n",
    "        dicc = inicializar_diccionario(characteristics + phrases)\n",
    "        if 'description' not in df:\n",
    "            dicc_list.append(dicc)\n",
    "            continue\n",
    "        description = list(df['description'])\n",
    "        if type(description[i]) != type(\"\"):\n",
    "            dicc_list.append(dicc)\n",
    "            continue\n",
    "        words = description[i].split()\n",
    "        lenght = len(words)\n",
    "        for j in range(0, lenght):\n",
    "            (wordBelongs, offset, index) = encontrar_frase(words, j, phrases)\n",
    "            if wordBelongs:\n",
    "                j += offset\n",
    "                if j >= lenght:\n",
    "                    break\n",
    "                dicc[phrases[index]] = true\n",
    "            if words[j].lower() in characteristics:\n",
    "                dicc[words[j].lower()] = true\n",
    "        dicc_list.append(dicc)\n",
    "    return dicc_list\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "#\n",
    "# ------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones de filtrado del data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#----------------------------------------------------------------------\n",
    "# Filtro de propiedades con precio calculable. Devuelve 1 si es válido. \n",
    "# De lo contrario, nan (Not A Number)\n",
    "#----------------------------------------------------------------------\n",
    "def filterPercentage(array):\n",
    "    priceUSD, usdM2, surfaceTotal = array\n",
    "    if priceUSD <= 0:\n",
    "        return np.nan\n",
    "    price = usdM2 * surfaceTotal\n",
    "    dif = abs(price - priceUSD)\n",
    "    if ((dif / priceUSD) * 100) <= 10:\n",
    "        return 1\n",
    "    return np.nan\n",
    "#----------------------------------------------------------------------\n",
    "# Filtro de propiedades con precio calculable. Devuelve 1 si es válido. \n",
    "# De lo contrario, nan (Not A Number)\n",
    "#----------------------------------------------------------------------\n",
    "def filterImposibles(array):\n",
    "    priceUSD, usdM2, surfaceTotal = array\n",
    "    if (np.isnan(surfaceTotal) or surfaceTotal <= 0) and not np.isnan(priceUSD) and not np.isnan(usdM2):\n",
    "        return 1\n",
    "    if np.isnan(priceUSD) and (not np.isnan(surfaceTotal) or surfaceTotal > 0) and not np.isnan(usdM2):\n",
    "        return 1\n",
    "    if np.isnan(usdM2) and (not np.isnan(surfaceTotal) or surfaceTotal > 0) and not np.isnan(priceUSD):\n",
    "        return 1\n",
    "    if not np.isnan(usdM2) and (not np.isnan(surfaceTotal) or surfaceTotal > 0) and not np.isnan(priceUSD):\n",
    "        return 1\n",
    "    return np.nan\n",
    "#----------------------------------------------------------------------\n",
    "# Cálculo del precio aproximado de venta\n",
    "#----------------------------------------------------------------------\n",
    "def fillPrice(array):\n",
    "    priceUSD, usdM2, surfaceTotal = array\n",
    "    if np.isnan(priceUSD) and not np.isnan(usdM2):\n",
    "        return (usdM2 * surfaceTotal)\n",
    "    return priceUSD\n",
    "#----------------------------------------------------------------------\n",
    "# Cálculo del precio del metro cuadrado\n",
    "#----------------------------------------------------------------------\n",
    "def fillM2(array):\n",
    "    priceUSD, usdM2, surfaceTotal = array\n",
    "    if surfaceTotal <= 0:\n",
    "        return np.nan\n",
    "    if not np.isnan(priceUSD) and np.isnan(usdM2):\n",
    "        return (priceUSD / surfaceTotal)\n",
    "    return usdM2\n",
    "#----------------------------------------------------------------------\n",
    "# Cálculo de la superficie\n",
    "#----------------------------------------------------------------------\n",
    "def fillSurface(array):\n",
    "    priceUSD, usdM2, surfaceTotal = array\n",
    "    if not np.isnan(priceUSD) and np.isnan(usdM2):\n",
    "        return (priceUSD / usdM2)\n",
    "    return surfaceTotal\n",
    "#----------------------------------------------------------------------\n",
    "# Obtenemos el año y mes del nombre de archivo\n",
    "#----------------------------------------------------------------------\n",
    "def addDate(date, df):\n",
    "    date_splitted = archive.split('-')\n",
    "    month = date_splitted[3]\n",
    "    year = date_splitted[2]\n",
    "    date = year + '-' + month\n",
    "    size = len(df.index)\n",
    "    dates = pd.Series([date for i in range(0, size)])\n",
    "    # y lo ponemos como dato en una columna\n",
    "    df['date'] = dates\n",
    "    df.loc[:, ['date']] = pd.to_datetime(df['date'], errors = 'coerce')\n",
    "    return df\n",
    "#----------------------------------------------------------------------\n",
    "# Durante la carga de datos, se eliminan ciertas columnas que nos \n",
    "#resultan irrelevantes para el trabajo\n",
    "#----------------------------------------------------------------------\n",
    "def filterUnnecesaryColumns(df, isId):\n",
    "    if 'surface_covered_in_m2' in df:\n",
    "        df.drop('surface_covered_in_m2', axis = 1, inplace = True)\n",
    "    if 'country_name' in df:\n",
    "        df.drop('country_name', axis = 1, inplace = True)\n",
    "    if 'price_aprox_local_currency' in df:\n",
    "        df.drop('price_aprox_local_currency', axis = 1, inplace = True)\n",
    "    if 'expenses' in df:\n",
    "        df.drop('expenses', axis = 1, inplace = True)\n",
    "    if 'properati_url' in df:\n",
    "        df.drop('properati_url', axis = 1, inplace = True)\n",
    "    if 'extra' in df:\n",
    "        df.drop('extra', axis = 1, inplace = True)\n",
    "    if 'geonames_id' in df:\n",
    "        df.drop('geonames_id', axis = 1, inplace = True)\n",
    "    if 'image_thumbnail' in df:\n",
    "        df.drop('image_thumbnail', axis = 1, inplace = True)\n",
    "    if 'operation' in df:\n",
    "        df.drop('operation', axis = 1, inplace = True)\n",
    "    if 'created_on' in df:\n",
    "        df.drop('created_on', axis = 1, inplace = True)\n",
    "    if 'lat-lon' in df:\n",
    "        df.drop('lat-lon', axis = 1, inplace = True)\n",
    "    if 'currency' in df:\n",
    "        df.drop('currency', axis = 1, inplace = True)\n",
    "    if 'title' in df:\n",
    "        df.drop('title', axis = 1, inplace = True)\n",
    "    if not isId and 'id' in df:\n",
    "        df.drop('id', axis = 1, inplace = True)\n",
    "    if 'price_aprox_local_currency' in df:\n",
    "        df.drop('price_aprox_local_currency', axis = 1, inplace = True)\n",
    "    if 'price_aprox_usd' in df and 'price' in df:\n",
    "        df.drop('price', axis = 1, inplace = True)\n",
    "    if 'extra' in df and 'price' in df:\n",
    "        df.drop('extra', axis = 1, inplace = True)\n",
    "    return df\n",
    "#----------------------------------------------------------------------\n",
    "# ADD DESCRIPTIONS COLUMNS\n",
    "#----------------------------------------------------------------------\n",
    "def addDescriptionColumns(df, columDict):\n",
    "    size = len(df.index)\n",
    "    description = list(df[columDict])\n",
    "    keys = description[0].keys()\n",
    "    for key in keys:\n",
    "        colum = []\n",
    "        for i in range(0, size):\n",
    "            value = description[i][key]\n",
    "            colum.append(value)\n",
    "        df[key] = colum\n",
    "    return df\n",
    "#----------------------------------------------------------------------\n",
    "# CHANGE PLACE WITH PARENT NAMES COLUMN TO NUMBER\n",
    "#----------------------------------------------------------------------\n",
    "def changePlaceWithParentsNamesColumn(df):    \n",
    "    listPlaces = df['place_with_parent_names'].tolist()\n",
    "    size = len(listPlaces)\n",
    "    for i in range(0, size):\n",
    "        listPlaces[i] = PlaceToNumber(listPlaces[i])\n",
    "    df['place_with_parent_names'] = listPlaces\n",
    "    return df\n",
    "#----------------------------------------------------------------------\n",
    "# PLACE TO NUMBER\n",
    "#----------------------------------------------------------------------\n",
    "def PlaceToNumber(x):\n",
    "    CF = 0\n",
    "    GBA = 1\n",
    "    x = str(x)\n",
    "    if 'Capital Federal' in x:\n",
    "        return CF\n",
    "    else:\n",
    "        return GBA\n",
    "#----------------------------------------------------------------------\n",
    "# CHANGE PROPERTY TYPE COLUMN TO NUMBER\n",
    "#----------------------------------------------------------------------\n",
    "def changePropertyTypeColumn(df):    \n",
    "    listPropertyType = df['property_type'].tolist()\n",
    "    size = len(listPropertyType)\n",
    "    for i in range(0, size):\n",
    "        listPropertyType[i] = propertyTypeToNumber(listPropertyType[i])\n",
    "    df['property_type'] = listPropertyType\n",
    "    return df\n",
    "#----------------------------------------------------------------------\n",
    "# PROPERTY TYPE TO NUMBER\n",
    "#----------------------------------------------------------------------\n",
    "def propertyTypeToNumber(x):\n",
    "    ph = 0\n",
    "    apartment = 1\n",
    "    house = 2\n",
    "    store = 3\n",
    "    if x.lower() == \"apartment\" or x.lower() == \"departamento\":\n",
    "        return apartment\n",
    "    if x.lower() == \"ph\":\n",
    "        return ph\n",
    "    if x.lower() == \"house\" or x.lower() == \"casa\":\n",
    "        return house\n",
    "    if x.lower() == \"store\":\n",
    "        return store\n",
    "#----------------------------------------------------------------------\n",
    "# Inclui cero si es casa y floor es nan\n",
    "#----------------------------------------------------------------------\n",
    "def aggFloor(floor):\n",
    "    if np.isnan(floor):\n",
    "        return 0\n",
    "    else:\n",
    "        return floor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = []\n",
    "archivesProceced = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loop principal del filtrado de cada dataframe del set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "properati-AR-2017-05-01-properties-sell.csv\n",
      "properati-AR-2014-01-01-properties-sell.csv\n",
      "properati-AR-2013-08-01-properties-sell.csv\n",
      "properati-AR-2015-04-01-properties-sell.csv\n",
      "properati-AR-2014-02-01-properties-sell.csv\n",
      "properati-AR-2013-09-01-properties-sell.csv\n",
      "properati-AR-2016-09-01-properties-sell.csv\n",
      "properati-AR-2017-01-01-properties-sell.csv\n",
      "properati-AR-2013-10-01-properties-sell.csv\n",
      "properati-AR-2015-05-01-properties-sell.csv\n",
      "properati-AR-2013-12-01-properties-sell.csv\n",
      "properati-AR-2014-05-01-properties-sell.csv\n",
      "properati-AR-2014-11-01-properties-sell.csv\n",
      "properati-AR-2014-09-01-properties-sell.csv\n",
      "properati-AR-2015-02-01-properties-sell.csv\n",
      "properati-AR-2016-08-01-properties-sell.csv\n",
      "properati-AR-2016-01-01-properties-sell.csv\n",
      "properati-AR-2016-11-01-properties-sell.csv\n",
      "properati-AR-2015-08-01-properties-sell.csv\n",
      "properati-AR-2017-03-01-properties-sell.csv\n",
      "properati-AR-2014-12-01-properties-sell.csv\n",
      "properati-AR-2015-12-01-properties-sell.csv\n",
      "properati-AR-2016-06-01-properties-sell.csv\n",
      "properati-AR-2015-06-01-properties-sell.csv\n",
      "properati-AR-2014-08-01-properties-sell.csv\n",
      "properati-AR-2016-04-01-properties-sell.csv\n",
      "properati-AR-2015-01-01-properties-sell.csv\n",
      "properati-AR-2014-06-01-properties-sell.csv\n",
      "properati-AR-2017-02-01-properties-sell.csv\n",
      "properati-AR-2013-11-01-properties-sell.csv\n",
      "properati-AR-2016-05-01-properties-sell.csv\n",
      "properati-AR-2015-03-01-properties-sell.csv\n",
      "properati-AR-2016-07-01-properties-sell.csv\n",
      "properati-AR-2014-07-01-properties-sell.csv\n",
      "properati-AR-2014-10-01-properties-sell.csv\n",
      "properati-AR-2015-11-01-properties-sell.csv\n",
      "properati-AR-2014-04-01-properties-sell.csv\n",
      "properati-AR-2017-06-06-properties-sell.csv\n",
      "properati-AR-2014-03-01-properties-sell.csv\n",
      "properati-AR-2017-06-01-properties-sell.csv\n",
      "properati-AR-2016-12-01-properties-sell.csv\n",
      "properati-AR-2015-10-01-properties-sell.csv\n",
      "properati-AR-2015-07-01-properties-sell.csv\n",
      "properati-AR-2015-09-01-properties-sell.csv\n",
      "properati-AR-2016-03-01-properties-sell.csv\n",
      "properati-AR-2017-04-01-properties-sell.csv\n",
      "properati-AR-2017-07-03-properties-sell.csv\n",
      "properati-AR-2016-02-01-properties-sell.csv\n",
      "properati-AR-2016-10-01-properties-sell.csv\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"# Ruta de la carpeta con los archivos de datos modificados\n",
    "root = \"./properties/\"\n",
    "indexAcum = 0\n",
    "for archive in listdir(root):\n",
    "    if \".csv\" not in archive:\n",
    "        continue\n",
    "    if archive in archivesProceced:\n",
    "        continue\n",
    "    df = pd.read_csv(root + archive, low_memory = False)\n",
    "    \n",
    "    df = df.loc[df.place_with_parent_names.str.contains('Capital Federal') \\\n",
    "        | df.place_with_parent_names.str.contains('Bs.As. G.B.A.'), :]\n",
    "    \n",
    "    # Durante la carga de datos, se eliminan ciertas columnas que nos \n",
    "    # resultan irrelevantes para el trabajo.\n",
    "    df = filterUnnecesaryColumns(df, False)\n",
    "\n",
    "    # En algunos casos, es necesario renombrar algunas columnas\n",
    "    if 'price_aprox_usd' not in df:\n",
    "        df.rename(columns = {'price': 'price_aprox_usd'}, inplace = True)\n",
    "    if 'surface_total_in_m2' not in df:\n",
    "        df.rename(columns = {'surface_in_m2': 'surface_total_in_m2'}, \\\n",
    "            inplace = True)\n",
    "\n",
    "    # Aquí reconvertimos algunas columnas a punto flotante\n",
    "    df.loc[:, 'price_aprox_usd'] = df.loc[:, ['price_aprox_usd']]\\\n",
    "        .apply(lambda x: float(x), axis = 1)\n",
    "    df.loc[:, 'price_usd_per_m2'] = df.loc[:, ['price_usd_per_m2']]\\\n",
    "        .apply(lambda x: float(x), axis = 1)\n",
    "\n",
    "    # Obtenemos el año y mes del nombre de archivo\n",
    "    df = addDate(archive, df)\n",
    "\n",
    "    # Antes de filtrar me fijo si puedo recuperar la superficie del campo descripcion\n",
    "    df['surface_total_in_m2'] = getSurface(df)\n",
    "    \n",
    "    # Aquí aplicamos el filtro antes declarado\n",
    "    df['filter1'] = df.loc[:, ['price_aprox_usd', 'price_usd_per_m2', \\\n",
    "            'surface_total_in_m2']].apply(lambda x: filterImposibles(x), axis = 1)\n",
    "    df = df[df['filter1'] == 1]\n",
    "    df.drop('filter1', axis = 1, inplace = True)\n",
    "    \n",
    "    size = len(df.index)\n",
    "    if size == 0:\n",
    "        continue\n",
    "    \n",
    "    df.loc[:, ['price_aprox_usd']] = df.loc[:, ['price_aprox_usd', \\\n",
    "            'price_usd_per_m2', 'surface_total_in_m2']].apply(lambda x: fillPrice(x), axis = 1)\n",
    "    \n",
    "    df.loc[:, ['price_usd_per_m2']] = df.loc[:, ['price_aprox_usd', \\\n",
    "            'price_usd_per_m2', 'surface_total_in_m2']].apply(lambda x: fillM2(x), axis = 1)\n",
    "    \n",
    "    df.loc[:, ['surface_total_in_m2']] = df.loc[:, ['price_aprox_usd', \\\n",
    "            'price_usd_per_m2', 'surface_total_in_m2']].apply(lambda x: fillSurface(x), axis = 1)\n",
    "    \n",
    "    df['filter2'] = df.loc[:, ['price_aprox_usd', 'price_usd_per_m2', \\\n",
    "            'surface_total_in_m2']].apply(lambda x: filterPercentage(x), axis = 1)\n",
    "    df = df[df['filter2'] == 1]\n",
    "    df.drop('filter2', axis = 1, inplace = True)\n",
    "    \n",
    "    #-------------------------------------------------------------\n",
    "    df.loc[:, ['place_with_parent_names']] = df.loc[:, ['place_with_parent_names']]\\\n",
    "    .apply(lambda x: PlaceToNumber(x), axis = 1)\n",
    "    df = changePropertyTypeColumn(df)\n",
    "    #df.loc[:, ['floor']] = df.loc[:, ['floor']].apply(lambda x: aggFloor(x), axis = 1)\n",
    "    #-------------------------------------------------------------\n",
    "    \n",
    "    # Si el filtrado es tal que me quedo sin dataframe, \n",
    "    # entonces salto a la siguiente iteracion\n",
    "    size = len(df.index)\n",
    "    if size == 0:\n",
    "        continue\n",
    "    \n",
    "    #Obtengo los campos de descripcion\n",
    "    df['rooms'] = getRooms(df)\n",
    "    df['description'] = crear_diccionario_descripcion(df)\n",
    "    df = addDescriptionColumns(df, 'description')\n",
    "    df.drop('description', axis = 1, inplace = True)\n",
    "    \n",
    "    # Finalmente, guardamos los archivos modificados.\n",
    "    indexAcum += size\n",
    "    newIndex = [i for i in range(indexAcum, indexAcum+size)]\n",
    "    df.reindex(newIndex)\n",
    "    print archive\n",
    "    properties.append(df)\n",
    "    archivesProceced.append(archive)\n",
    "#-------------------------------------------------------------------\n",
    "#-------------------------------------------------------------------\n",
    "#Genero un nuevo csv con la concatenacion de todos ellos en uno solo\n",
    "general = pd.concat(properties)\n",
    "\n",
    "#Borro las columnas vacias\n",
    "for column in general.columns.values:\n",
    "    if 'unnamed' not in column.lower():\n",
    "        continue\n",
    "    general.drop(column, axis = 1, inplace = True)\n",
    "\n",
    "general.loc[:, ['date']] = pd.to_datetime(general['date'], errors = 'coerce')\n",
    "\n",
    "#Grabo la concatenacion en un unico csv\n",
    "try:\n",
    "    general.to_csv(\"propertiesConCat.csv\", index = True, header = True, \\\n",
    "        sep = ',', encoding = 'utf-8-sig')\n",
    "    print('Done')\n",
    "except value:\n",
    "    print('Error')\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n"
     ]
    }
   ],
   "source": [
    "print len(archivesProceced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proceso de filtrado y acomodamiento de los datos para entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"propertiesConCat.csv\", low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictDf = pd.read_csv(\"properati_dataset_testing_noprice.csv\", low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# FUNCTIONS OF PROCCES OF TRAIN DATA\n",
    "#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "#---------------------------------------------------------\n",
    "# HASH PLACES\n",
    "#---------------------------------------------------------\n",
    "def hashPlaces(df, predictDf):\n",
    "    placesHash = {}\n",
    "    groupedPlaces = df.loc[:, ['place_name', 'floor']].groupby('place_name').agg([np.size]).reset_index()\n",
    "    places = groupedPlaces['place_name'].tolist()\n",
    "    groupedPlaces = predictDf.loc[:, ['place_name', 'floor']].groupby('place_name').agg([np.size]).reset_index()\n",
    "    places = places + groupedPlaces['place_name'].tolist()\n",
    "    size = len(places)\n",
    "    for i in range(0, size):\n",
    "        if places[i] in placesHash:\n",
    "            continue\n",
    "        placesHash[places[i]] = 0\n",
    "    keys = placesHash.keys()\n",
    "    size = len(keys)\n",
    "    for i in range(0, size):\n",
    "        placesHash[keys[i]] = i\n",
    "    placesHash[\"no place\"] = size\n",
    "    return placesHash\n",
    "#---------------------------------------------------------\n",
    "# PROCCES NO PLACES\n",
    "#---------------------------------------------------------\n",
    "def processNoPlaces(df):\n",
    "    places = df['place_name'].tolist()\n",
    "    size = len(places)\n",
    "    for i in range(0, size):\n",
    "        if type(places[i]) != type(\"\"):\n",
    "            places[i] = \"no place\"\n",
    "    df['place_name'] = places\n",
    "    return df\n",
    "#---------------------------------------------------------\n",
    "# CNVERT PLACES TO HASH NUMBER\n",
    "#---------------------------------------------------------\n",
    "def convertPlacesToHashNumber(df, placesHash):   \n",
    "    placesDataTrain = df['place_name'].tolist()\n",
    "    size = len(placesDataTrain)\n",
    "    count = 0\n",
    "    hashSize = len(placesHash.keys())\n",
    "    for i in range(0, size):\n",
    "        placeName = placesDataTrain[i]\n",
    "        placesDataTrain[i] = placesHash[placeName]\n",
    "    df['place_name'] = placesDataTrain\n",
    "    return df\n",
    "#---------------------------------------------------------\n",
    "# DELETE EXTRA COLUMNS\n",
    "#---------------------------------------------------------\n",
    "def deleteExtraColumns(df):\n",
    "    columns = [\n",
    "        'price_aprox_usd.1', \n",
    "        'Unnamed: 0', \n",
    "        'price_per_m2', \n",
    "        'date',\n",
    "        'lat',\n",
    "        'lon',\n",
    "        'floor', \n",
    "        'state_name', \n",
    "        'price_usd_per_m2'\n",
    "    ]\n",
    "    df.drop(columns, axis = 1, inplace = True)\n",
    "    columns = list(df.columns.values)\n",
    "    for column in columns:\n",
    "        if \"unnamed\" in column.lower():\n",
    "            df.drop(column, axis = 1, inplace = True) \n",
    "    return df\n",
    "#---------------------------------------------------------\n",
    "# DELETE TRASH COLUMNS\n",
    "#---------------------------------------------------------\n",
    "def deleteTrashColumns(df):\n",
    "    columns = list(df.columns.values)\n",
    "    for column in columns:\n",
    "        if \"unnamed\" in column.lower():\n",
    "            df.drop(column, axis = 1, inplace = True) \n",
    "    return df\n",
    "#---------------------------------------------------------\n",
    "# PROCESS TRAIN SET\n",
    "#---------------------------------------------------------\n",
    "def ProcessTrainSet(df, withPrice):\n",
    "    df.dropna(axis=0, how='any', subset=list(df.columns.values), inplace=True)\n",
    "    \n",
    "    target = df['price_aprox_usd'].tolist()\n",
    "    if withPrice:\n",
    "        df.drop('price_aprox_usd', axis = 1, inplace = True)\n",
    "    \n",
    "    columns = list(df.columns.values)\n",
    "    data = list(df.values)\n",
    "    return data, target\n",
    "\n",
    "#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "# FUNCTIONS OF PROCCES OF TEST DATA\n",
    "#+++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n",
    "\n",
    "#---------------------------------------------------------\n",
    "# DELETE COLUMNS TEST DATA\n",
    "#---------------------------------------------------------\n",
    "def deleteColumnsTestData(df, columnsToEvaluate):\n",
    "    columns = list(df.columns.values)\n",
    "    for column in columns:\n",
    "        if column in columnsToEvaluate:\n",
    "            continue\n",
    "        df.drop(column, axis = 1, inplace = True)\n",
    "    return df\n",
    "#---------------------------------------------------------\n",
    "# PRE PROCCES TEST DATA\n",
    "#---------------------------------------------------------\n",
    "def preProcessTestData(df, placesHash):\n",
    "    df = filterUnnecesaryColumns(df, True)\n",
    "    df['rooms'] = getRooms(df)\n",
    "    df['surface_total_in_m2'] = getSurface(df)\n",
    "    df['description'] = crear_diccionario_descripcion(df)\n",
    "    df = processNoPlaces(df)\n",
    "    df = convertPlacesToHashNumber(df, placesHash)\n",
    "    df = addDescriptionColumns(df, 'description')\n",
    "    df = changePlaceWithParentsNamesColumn(df)\n",
    "    df = changePropertyTypeColumn(df)\n",
    "    return df\n",
    "#---------------------------------------------------------\n",
    "# GET DATA AS LIST\n",
    "#---------------------------------------------------------\n",
    "def GetDataAsList(df):\n",
    "    columns = list(df.columns.values)\n",
    "    data = list(df.values)\n",
    "    return data\n",
    "#---------------------------------------------------------\n",
    "# CREATE DICTIONARY SURFACES MEAN\n",
    "#---------------------------------------------------------\n",
    "def createDictionarySurfacesMean(df):\n",
    "    df = df.loc[:, ['surface_total_in_m2', 'place_name']].groupby('place_name')\\\n",
    "                .agg([np.mean, np.size]).reset_index()\n",
    "    surfacesMeanByPlace = df[('surface_total_in_m2', 'mean')].tolist()\n",
    "    places = df['place_name'].tolist()\n",
    "    size = len(surfacesMeanByPlace)\n",
    "    surface = {}\n",
    "    for i in range(0, size):\n",
    "        surface[places[i]] = surfacesMeanByPlace[i]\n",
    "    return surface\n",
    "#---------------------------------------------------------\n",
    "# VALIDATE SURFACES MEAN\n",
    "#---------------------------------------------------------\n",
    "def validateSufaceMean(df, surfaceMeanDicc, places):\n",
    "    surfaces = df['surface_total_in_m2'].tolist()\n",
    "    size = len(surfaces)\n",
    "    for i in range(0, size):\n",
    "        if surfaces[i] != 0:\n",
    "            continue\n",
    "        surfaceMean = surfaceMeanDicc[places[i]]\n",
    "        if np.isnan(surfaceMean):\n",
    "            continue\n",
    "        surfaces[i] = surfaceMean\n",
    "    df['surface_total_in_m2'] = surfaces\n",
    "    return df\n",
    "#---------------------------------------------------------\n",
    "# SAVE FINAL DF\n",
    "#---------------------------------------------------------\n",
    "def saveFinalDF(predictions, ids):\n",
    "    final = pd.DataFrame()\n",
    "    final['id'] = ids\n",
    "    final['price_usd'] = predictions\n",
    "    final = final.reset_index()\n",
    "    final.drop('index', axis = 1, inplace = True)\n",
    "    final.to_csv(\"properati_dataset_sample_submision.csv\", index = True, header = True, sep = ',', encoding = 'utf-8-sig')\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "placesHash = hashPlaces(df, predictDf)\n",
    "df = processNoPlaces(df)\n",
    "df = convertPlacesToHashNumber(df, placesHash)\n",
    "df = deleteExtraColumns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"dataTrain.csv\", index = True, header = True, sep = ',', encoding = 'utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataTrain.csv\", low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = deleteTrashColumns(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTrain, targetTrain = ProcessTrainSet(df, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size:  1366863\n",
      "target size:  1366863\n",
      "columns size:  15\n"
     ]
    }
   ],
   "source": [
    "columns = list(df.columns.values)\n",
    "print \"data size: \", len(dataTrain)\n",
    "print \"target size: \", len(targetTrain)\n",
    "print \"columns size: \", len(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preproceso del set de test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cancha de tenis',\n",
       " 'club house',\n",
       " 'cochera',\n",
       " 'comedor',\n",
       " 'futbol 5',\n",
       " 'living',\n",
       " 'pileta',\n",
       " 'piscina',\n",
       " 'place_name',\n",
       " 'place_with_parent_names',\n",
       " 'property_type',\n",
       " 'rooms',\n",
       " 'sector de juegos infantiles',\n",
       " 'seguridad las 24 hs',\n",
       " 'surface_total_in_m2']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columnsToEvaluate = columns\n",
    "columnsToEvaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictDf = pd.read_csv(\"properati_dataset_testing_noprice.csv\", low_memory = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = predictDf\n",
    "places = aux['place_name'].tolist()\n",
    "surfaceMeanDicc = createDictionarySurfacesMean(aux)\n",
    "predictDf = preProcessTestData(predictDf, placesHash)\n",
    "predictDf = validateSufaceMean(predictDf, surfaceMeanDicc, places)\n",
    "ids = predictDf['id']\n",
    "predictDf = deleteColumnsTestData(predictDf, columnsToEvaluate)\n",
    "data = GetDataAsList(predictDf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size:  14166\n",
      "df size:  14166\n",
      "columns size:  15\n"
     ]
    }
   ],
   "source": [
    "print \"data size: \", len(data)\n",
    "print \"df size: \", len(predictDf.index)\n",
    "print \"columns size: \", len(predictDf.columns.values)\n",
    "#row should be 14166"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PreProcces sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = pd.read_csv(\"propertiesConCat.csv\", low_memory = False)\n",
    "sample = sample.sample(frac=0.3, replace=True)\n",
    "sample = processNoPlaces(sample)\n",
    "sample = convertPlacesToHashNumber(sample, placesHash)\n",
    "sample = deleteExtraColumns(sample)\n",
    "dataSample, targetSample = ProcessTrainSet(sample, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data size:  409715\n",
      "target size:  409715\n",
      "columns size:  15\n"
     ]
    }
   ],
   "source": [
    "columns = list(sample.columns.values)\n",
    "print \"data size: \", len(dataSample)\n",
    "print \"target size: \", len(targetSample)\n",
    "print \"columns size: \", len(columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediccion "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entreno el set de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=True)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(dataTrain, targetTrain)\n",
    "lr.score(dataTrain, targetTrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediccion a traves de un samole para ver el error "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision sample:  0.0897540746339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f44259d0310>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEVCAYAAAAckrn/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nf3Fv2W4N0U/LAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4423a268d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = lr.predict(dataSample)\n",
    "print \"precision sample: \", lr.score(dataSample, targetSample)\n",
    "f, ax = plt.subplots(1)\n",
    "ax.hist(targetSample - predictions, bins=50, alpha=0.7)\n",
    "ax.set_title('Histograma de residuales')\n",
    "ax.text(0.95, 0.90, 'Media de residuales: {:.3e}'.format(np.mean(targetSample - predictions)),\n",
    "        transform=ax.transAxes, verticalalignment='top', horizontalalignment='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediccion del set de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = lr.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = saveFinalDF(predictions, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3632</td>\n",
       "      <td>1.247484e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3633</td>\n",
       "      <td>5.288541e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2263404</td>\n",
       "      <td>8.702557e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2263405</td>\n",
       "      <td>4.927972e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2263406</td>\n",
       "      <td>6.199079e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     price_usd\n",
       "0     3632  1.247484e+07\n",
       "1     3633  5.288541e+06\n",
       "2  2263404  8.702557e+06\n",
       "3  2263405  4.927972e+06\n",
       "4  2263406  6.199079e+06"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformacion no lineal a lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  (Este metodo da precios demasiado altos y es peor que el lineal hecho en el paso anterior)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si tomamos como ejemplo una función f que toma la forma :  f(x) = a + bx + cx²\n",
    "\n",
    "La función f es no lineal en función de x pero si es lineal en función de los parámetros desconocidos a, b, y c. O visto de otra manera: podemos sustituir nuestras variables x por un array z tal que: z = [1, x, x²]. Con el que podríamos reescribir nuestra función f como f(z) = a z0 + bz1 + c*z2\n",
    "\n",
    "Scikit-learn tiene un objeto PolynomialFeatures que nos va a servir para convertir nuestra variable x en un array z del tipo z = [1, x, x2, …, n^n], que es lo que nos interesa.\n",
    "\n",
    "El resultado de esa transformación se la pasamos a nuestro modelo Ridge. Para facilitar la tarea en este tipo de casos —donde se realizan varios pasos que van desde el pre-tratamiento de los datos hasta un posible post-tratamiento pasando por el entrenamiento—, podemos hacer uso de las Pipeline que nos permiten encadenar multiples estimadores en uno. Esto es especialmente útil cuando hay secuencia de pasos predefinidos en el procesado de datos con, por ejemplo, selección de atributos, normalización y clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18679831133031699"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly = PolynomialFeatures(degree = 2)\n",
    "z = poly.fit_transform(dataTrain)\n",
    "lr = LinearRegression(normalize=True)\n",
    "lr.fit(z, targetTrain)\n",
    "lr.score(z, targetTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampleTransformed = poly.fit_transform(dataSample)\n",
    "predictionsSamplePlynomial = lr.predict(sampleTransformed)\n",
    "print \"precision sample: \", lr.score(dataSample, targetSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataTransformed = poly.fit_transform(data)\n",
    "predictions = lr.predict(DataTransformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = saveFinalDF(predictions, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3632</td>\n",
       "      <td>1.001339e+21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3633</td>\n",
       "      <td>8.158107e+21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2263404</td>\n",
       "      <td>5.498861e+21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2263405</td>\n",
       "      <td>8.590666e+20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2263406</td>\n",
       "      <td>8.654199e+20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     price_usd\n",
       "0     3632  1.001339e+21\n",
       "1     3633  8.158107e+21\n",
       "2  2263404  5.498861e+21\n",
       "3  2263405  8.590666e+20\n",
       "4  2263406  8.654199e+20"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decicion Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precisión entranamiento:  0.20, depth:  3\n",
      "precisión entranamiento:  0.27, depth:  4\n",
      "precisión entranamiento:  0.32, depth:  5\n",
      "precisión entranamiento:  0.41, depth:  6\n",
      "precisión entranamiento:  0.43, depth:  7\n",
      "precisión entranamiento:  0.45, depth:  8\n",
      "precisión entranamiento:  0.47, depth:  9\n",
      "precisión entranamiento:  0.49, depth:  10\n",
      "precisión entranamiento:  0.51, depth:  11\n",
      "precisión entranamiento:  0.55, depth:  12\n",
      "precisión entranamiento:  0.59, depth:  13\n",
      "precisión entranamiento:  0.62, depth:  14\n",
      "precisión entranamiento:  0.64, depth:  15\n",
      "precisión entranamiento:  0.67, depth:  16\n",
      "precisión entranamiento:  0.70, depth:  17\n",
      "precisión entranamiento:  0.73, depth:  18\n",
      "precisión entranamiento:  0.75, depth:  19\n",
      "precisión entranamiento:  0.76, depth:  20\n",
      "precisión entranamiento:  0.78, depth:  21\n",
      "precisión entranamiento:  0.79, depth:  22\n"
     ]
    }
   ],
   "source": [
    "maxDeepList = list(range(3, 23))\n",
    "regrList =  []\n",
    "for depth in maxDeepList:\n",
    "    regr = DecisionTreeRegressor(max_depth = depth)\n",
    "    regr.fit(dataTrain, targetTrain)\n",
    "    y_1 = regr.predict(data)\n",
    "    print(\"precisión entranamiento: {0: .2f}, depth: {1: }\".format(regr.score(dataTrain, targetTrain), depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit regression model\n",
    "decicionTree = DecisionTreeRegressor(max_depth=100)\n",
    "decicionTree.fit(dataTrain, targetTrain)\n",
    "# Predict\n",
    "predictionDT = decicionTree.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision sample:  0.899801228983\n"
     ]
    }
   ],
   "source": [
    "samplePredictionDT = decicionTree.predict(dataSample)\n",
    "print \"precision sample: \", decicionTree.score(dataSample, targetSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = saveFinalDF(predictionDT, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3632</td>\n",
       "      <td>330000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3633</td>\n",
       "      <td>95000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2263404</td>\n",
       "      <td>125000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2263405</td>\n",
       "      <td>105000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2263406</td>\n",
       "      <td>330000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  price_usd\n",
       "0     3632   330000.0\n",
       "1     3633    95000.0\n",
       "2  2263404   125000.0\n",
       "3  2263405   105000.0\n",
       "4  2263406   330000.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridgeRegression = linear_model.Ridge(alpha = .5)\n",
    "ridgeRegression.fit(dataTrain, targetTrain) \n",
    "predictionsRR = ridgeRegression.predict(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision sample:  0.0883556986071\n"
     ]
    }
   ],
   "source": [
    "samplePredictionRR = ridgeRegression.predict(dataSample)\n",
    "print \"precision sample: \", ridgeRegression.score(dataSample, targetSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = saveFinalDF(predictionsRR, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3632</td>\n",
       "      <td>1.247483e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3633</td>\n",
       "      <td>5.288584e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2263404</td>\n",
       "      <td>8.702583e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2263405</td>\n",
       "      <td>4.927980e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2263406</td>\n",
       "      <td>6.199083e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     price_usd\n",
       "0     3632  1.247483e+07\n",
       "1     3633  5.288584e+06\n",
       "2  2263404  8.702583e+06\n",
       "3  2263405  4.927980e+06\n",
       "4  2263406  6.199083e+06"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgeComplexity = linear_model.RidgeCV(alphas = [0.1, 1.0, 10.0])\n",
    "ridgeComplexity.fit(dataTrain, targetTrain)       \n",
    "ridgeComplexity.alpha_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.088456337638194049"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgeComplexity.score(dataTrain, targetTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision sample:  0.0856249719181\n"
     ]
    }
   ],
   "source": [
    "samplePredictionRC = ridgeComplexity.predict(dataSample)\n",
    "print \"precision sample: \", ridgeComplexity.score(dataSample, targetSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "RCPredictions = ridgeComplexity.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = saveFinalDF(RCPredictions, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3632</td>\n",
       "      <td>1.247478e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3633</td>\n",
       "      <td>5.289504e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2263404</td>\n",
       "      <td>8.703183e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2263405</td>\n",
       "      <td>4.928224e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2263406</td>\n",
       "      <td>6.199271e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id     price_usd\n",
       "0     3632  1.247478e+07\n",
       "1     3633  5.289504e+06\n",
       "2  2263404  8.703183e+06\n",
       "3  2263405  4.928224e+06\n",
       "4  2263406  6.199271e+06"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LARS Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.091261947135490171"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lars = linear_model.LassoLars(alpha=0.5)\n",
    "Lars.fit(dataTrain, targetTrain) \n",
    "Lars.score(dataTrain, targetTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision sample:  0.088308627118\n"
     ]
    }
   ],
   "source": [
    "samplePredictionLars = Lars.predict(dataSample)\n",
    "print \"precision sample: \", Lars.score(dataSample, targetSample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "LARSPredictions = reg.predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = saveFinalDF(LARSPredictions, ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_usd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3632</td>\n",
       "      <td>-421403.261019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3633</td>\n",
       "      <td>194659.708018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2263404</td>\n",
       "      <td>-172104.438379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2263405</td>\n",
       "      <td>-127896.770630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2263406</td>\n",
       "      <td>-57856.757259</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id      price_usd\n",
       "0     3632 -421403.261019\n",
       "1     3633  194659.708018\n",
       "2  2263404 -172104.438379\n",
       "3  2263405 -127896.770630\n",
       "4  2263406  -57856.757259"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF = RandomForestRegressor(n_estimators=1000)\n",
    "RF.fit(dataTrain, targetTrain)\n",
    "RF.socre(dataTrain, tragetTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RF.predict(dataSample)\n",
    "RF.socre(dataSample, tragetSample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
